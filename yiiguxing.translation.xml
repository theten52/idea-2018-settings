<application>
  <component name="AppStorage">
    <histories>
      <item value="Check if queue empty only if necessary." />
      <item value="2. If a task can be successfully queued, then we still need to double-check whether we should have added a thread (because existing ones died since last checking) or that the pool shut down since entry into this method. So we recheck state and if necessary roll back the enqueuing if stopped, or start a new thread if there are none." />
      <item value="If we cannot queue task, then we try to add a new thread. If it fails, we know we are shut down or saturated and so reject the task." />
      <item value="1. If fewer than corePoolSize threads are running, try to start a new thread with the given command as its first task. The call to addWorker atomically checks runState and workerCount, and so prevents false alarms that would add threads when it shouldn't, by returning false." />
      <item value="MAXIMUM CAPACITY" />
      <item value="Number of CPUS, to place bounds on some sizings" />
      <item value="DEFAULT CAPACITY" />
      <item value="Convert Exception to corresponding Error" />
      <item value="Unsafe mechanics" />
      <item value="stream" />
      <item value="drain To" />
      <item value="remaining Capacity" />
      <item value="CP Us" />
      <item value="While garbage collection takes care of most node reclamation issues that otherwise complicate nonblocking algorithms, care is taken to &quot;forget&quot; references to data, other nodes, and threads that might be held on to long-term by blocked threads. In cases where setting to null would otherwise conflict with main algorithms, this is done by changing a node's link to now point to the node itself. This doesn't arise much for Stack nodes (because blocked threads do not hang on to old head pointers), but references in Queue nodes must be aggressively forgotten to avoid reachability of everything any node has ever referred to since arrival." />
      <item value="Cleaning is done in different ways in queues vs stacks. For queues, we can almost always remove a node immediately in O(1) time (modulo retries for consistency checks) when it is cancelled. But if it may be pinned as the current tail, it must wait until some subsequent cancellation. For stacks, we need a potentially O(n) traversal to be sure that we can remove the node, but this can run concurrently with other threads accessing the stack." />
      <item value="Blocking is mainly accomplished using LockSupport parkunpark, except that nodes that appear to be the next ones to become fulfilled first spin a bit (on multiprocessors only). On very busy synchronous queues, spinning can dramatically improve throughput. And on less busy ones, the amount of spinning is small enough not to be noticeable." />
      <item value="1. The original algorithms used bit-marked pointers, but the ones here use mode bits in nodes, leading to a number of further adaptations. 2. SynchronousQueues must block threads waiting to become fulfilled. 3. Support for cancellation via timeout and interrupts, including cleaning out cancelled nodesthreads from lists to avoid garbage retention and memory depletion." />
      <item value="The algorithms here differ from the versions in the above paper in extending them for use in synchronous queues, as well as dealing with cancellation. The main differences include:" />
      <item value="The queue and stack data structures share many conceptual similarities but very few concrete details. For simplicity, they are kept distinct so that they can later evolve separately." />
      <item value="Both the queue and stack extend abstract class Transferer defining the single method transfer that does a put or a take. These are unified into a single method because in dual data structures, the put and take operations are symmetrical, so nearly all code can be combined. The resulting transfer methods are on the long side, but are easier to follow than they would be if broken up into nearly-duplicated parts." />
      <item value="A dual queue (and similarly stack) is one that at any given time either holds &quot;data&quot; -- items provided by put operations, or &quot;requests&quot; -- slots representing take operations, or is empty. A call to &quot;fulfill&quot; (i.e., a call requesting an item from a queue holding data or vice versa) dequeues a complementary node. The most interesting feature of these queues is that any operation can figure out which mode the queue is in, and act accordingly without needing locks." />
      <item value="This class implements extensions of the dual stack and dual queue algorithms described in &quot;Nonblocking Concurrent Objects with Condition Synchronization&quot;, by W. N. Scherer III and M. L. Scott. 18th Annual Conf. on Distributed Computing, Oct. 2004 (see also http:www.cs.rochester.eduuscottsynchronizationpseudocodeduals.html). The (Lifo) stack is used for non-fair mode, and the (Fifo) queue for fair mode. The performance of the two is generally similar. Fifo usually supports higher throughput under contention but Lifo maintains higher thread locality in common applications." />
      <item value="guarantees" />
      <item value="shrink" />
      <item value="of threads actively engaged in" />
      <item value="engaged" />
      <item value="corresponds" />
      <item value="contention" />
      <item value="reduce" />
      <item value="parallelism" />
      <item value="maintains" />
      <item value="thread" />
      <item value="Creates" />
      <item value="consistency" />
      <item value="sketch" />
      <item value="more" />
      <item value="Repeatedly" />
      <item value="or start a new thread if there are none." />
      <item value="enqueuing" />
      <item value="because existing ones died since last checking" />
      <item value="offer" />
      <item value="The call to addWorker atomically checks runState and workerCount, and so prevents false alarms that would add threads when it shouldn't, by returning false." />
      <item value="Proceed" />
      <item value="Executes the given task sometime in the future." />
      <item value="Proceed in 3 steps:" />
      <item value="excess" />
      <item value="Packing and unpacking ctl" />
      <item value="assert Timeout Preemptively" />
      <item value="姓氏" />
      <item value="第二节" />
    </histories>
    <option name="languageScores">
      <map>
        <entry key="CHINESE" value="1105" />
        <entry key="ENGLISH" value="1107" />
        <entry key="ESTONIAN" value="1" />
        <entry key="GERMAN" value="7" />
        <entry key="FRENCH" value="3" />
        <entry key="GALICIAN" value="1" />
        <entry key="LATIN" value="1" />
        <entry key="JAPANESE" value="1" />
        <entry key="ESPERANTO" value="2" />
        <entry key="ITALIAN" value="2" />
      </map>
    </option>
  </component>
  <component name="Cache">
    <option name="lastTrimTime" value="1614096681748" />
  </component>
  <component name="Settings">
    <option name="baiduTranslateSettings">
      <app-key>
        <option name="appId" value="20200402000411101" />
      </app-key>
    </option>
    <option name="youdaoTranslateSettings">
      <youdao-translate>
        <option name="appId" value="20200402000411101" />
      </youdao-translate>
    </option>
  </component>
</application>